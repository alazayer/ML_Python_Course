{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursera - Machine Learning with Python\n",
    "### Week 2 Material\n",
    "\n",
    "Date: March 17, 2020\n",
    "\n",
    "## Regression\n",
    "\n",
    "Is the process of predicting a continuous value. We have one dependent variable (y) and multiple independent variables (x)\n",
    "\n",
    "**Types of Regression:**\n",
    "\n",
    "Simple vs. Multiple regression (1 vs. multiple independent variables)\n",
    "\n",
    "Linear vs. Non-linear regression\n",
    "\n",
    "The lecture walks through a simple linear regrestion to fit a line (y = mx + b) by the least squares method.\n",
    "\n",
    "**Model Evaluation** \n",
    "\n",
    "*Training Accuracy*\n",
    "The percentage of correct prediction from the training sample set\n",
    "Not always good to have high training accuracy (Overfit)\n",
    "\n",
    "*Out of Sample accuracy*\n",
    "The percentage of correct predictions from a set that was not used in the training\n",
    "\n",
    "Using Train/Test split gives a more \"Out of Sample accuracy\" evaluation than testing the model on a trained set.\n",
    "\n",
    "However, it is important to train the model with all the data after testing for \"Out of sample accuracy\"\n",
    "\n",
    "Another even better method is **K-fold cross-validation** which does multiple Train/Testing splits using the same data set and averages the \"Out of sample accuracy\"\n",
    "\n",
    "**How to estimate Errors** \n",
    "\n",
    "\n",
    "Mean Absolute Error (MAE) $$MAE = \\frac{1}{n} \\sum_{j=1}^n |{y_j - \\hat{y}_j}|$$\n",
    "\n",
    "Mean Square Error (MSE) $$MSE = \\frac{1}{n} \\sum_{j=1}^n ({y_j - \\hat{y}_j})^2$$\n",
    "\n",
    "Root Mean Square Error (RMSE) $$RMSE = \\sqrt{\\frac{1}{n} \\sum_{j=1}^n ({y_j - \\hat{y}_j})^2}$$\n",
    "\n",
    "Relative Absolute Error (RAE) $$RAE = \\frac{\\sum_{j=1}^n |{y_j - \\hat{y}_j}|}{\\sum_{j=1}^n |{y_j - \\bar{y}_j}|}$$\n",
    "\n",
    "Relative Squared Error (RSE) $$RAE = \\frac{\\sum_{j=1}^n ({y_j - \\hat{y}_j})^2}{\\sum_{j=1}^n ({y_j - \\bar{y}_j})^2}$$\n",
    "\n",
    "\n",
    "$R^2$ is an indicator of how good the line fits the data $$R^2 = 1 - RSE$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "It can be used to identify the impact of an independent variable on a dependent variable. It follows the same concept as Linear Regression but with more independent variables:\n",
    "\n",
    "$$ \\hat{y} = \\theta^T X$$\n",
    "\n",
    "$$ \\theta^T = [\\theta_1, \\theta_2, \\theta_3,...], X = \\begin{bmatrix} 1 \\\\ x_1 \\\\ x_2 \\\\ ... \\end{bmatrix}$$\n",
    "\n",
    "Estimate $\\theta$ in this case may become expensive when using Least Squares. Instead, an Optimization algorithm (e.g. gradient descent) should be used.\n",
    "\n",
    "*Caution:* Using too many independent variables without any theoretical justification should be avoided since that could lead to overfitted models. \n",
    "\n",
    "You can check for linearity by using scatter plots before deciding whether to use linear or non-linear regression. If $R^2$ for all independent variables are greater than 0.7 then there is some linearity and linear regression can be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Regression\n",
    "\n",
    "**Types of Regression**\n",
    "\n",
    "1- Polynomial Regression: Polynomial regression can be expressed as a linear function and therefore can use least squares as well\n",
    "\n",
    "2- Non-linear Regression: the solution is a non-linear function of the parameters $\\theta$ and so least squares **cannot** be used \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "#### *3 Labs did not open from Week 2 - Multiple Linear, Polynomial and Non-linear Regression*\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
